# Simple Two-Layer Neural Network for MNIST Classification

This project demonstrates a two-layer neural network built from scratch using Python and NumPy, designed to classify handwritten digits from the MNIST dataset. The neural network consists of ReLU and Softmax activations and is trained using backpropagation and gradient descent.

![Sample Image](./images/sample_prediction.png) 

## Table of Contents

- [Project Overview](#project-overview)
- [Installation](#installation)
- [Usage](#usage)
- [Code Structure](#code-structure)
- [Examples](#examples)
- [License](#license)

## Project Overview

This project aims to implement a simple, fully-connected neural network from scratch without using any high-level deep learning libraries. It includes:
- Loading and preprocessing the MNIST dataset
- Building a neural network with two layers
- Training the model using gradient descent
- Testing the modelâ€™s performance on unseen data
- Visualizing predictions for sample images

## Installation

To get started, clone the repository and install the necessary libraries:

```bash
git clone https://github.com/your-username/mnist-neural-network.git
cd mnist-neural-network
